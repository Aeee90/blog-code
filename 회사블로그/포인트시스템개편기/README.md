# 포인트 시스템 개편기 #1 - 개발

올해 4월 중순부터 시작해 7월 말까지 진행된 포인트 시스템을 개편했던 경험을 공유하려고 합니다.  

기존에는 포인트라는 서비스 자체가 구축되어 있지 않았습니다.  
중앙 DB에 존재하는 포인트 테이블과 프로시저만 존재했습니다.  
그러다보니 모든 서비스가 필요하면 포인트 프로시저를 수행되는 구조였습니다.  
  
도메인 모델과 프로시저 내부에 문제가 있어 계속해서 이슈도 발생하던 상황이라 개편은 피할 수 없었습니다.  
  
신규 시스템을 오픈한다는 것은 서버와 배포 환경, 도메인 모델, 어플리케이션 등을 완전히 제로에서 만들어야 함을 의미했습니다.  
그 과정에서 저희가 했던 고민들을 공유하면 비슷한 상황에 있으신 분들에게 조금이나마 도움이 되지 않을까 싶어 작성했습니다.  
  
내용이 많아서 2파트로 나눴습니다.

1. 개발
2. 오픈 준비

## 1. 기술 스택

신규 포인트 시스템의 기술 스택은 다음과 같습니다.

* Java 8
* Querydsl 4.x
* Junit 4 & Spock
* Spring Boot 2.x
* Spring Cloud 2.x
* AWS Beanstalk
* AWS Aurora RDS
* AWS Elastic Cache - Redis
* AWS SQS
* Jenkins

어플리케이션쪽은 기존 Java & Spring 개발자분들이 쓰시는 기술 스택과 크게 차이가 안날것 같습니다.  
이외 나머지 기술들을 선택했던 이유들을 하나씩 소개하겠습니다.

### 1-1. Beanstalk vs EC2 & ASG (Auto Scaling Group)

처음 구축 할때는 AWS Beanstalk을 선택했습니다.

* 이미 회사에는 Beanstalk을 다양하게 쓰면서 쌓인 노하우가 있었습니다.
* ebextension으로 인해 빠르게 Nginx, 리눅스 커널들을 설정하고 서버 환경 구축이 가능했습니다.

이 2가지 이유로 Beanstalk을 선택 하고 실제 오픈까지 진행했습니다.  
  
하지만 오픈하고 난 뒤부터 Beanstalk의 단점이 하나씩 보이기 시작했습니다.  
(사실 그전에도 보였습니다만 애써 모른척한 것에 가까웠습니다.)  

* 한번 잘못 생성한 Beanstalk 환경을 수정하기가 어렵습니다.
    * 특히 잘못 생성한 Beanstalk 환경을 삭제하려면 1시간이 필요해 같은 이름의 Beanstalk으로 다시 생성하는데 대기 시간이 너무 길었습니다.
* 상세한 설정이 어렵습니다.
    * 예를 들어 Beanstalk 배포가 성공하면 알람을 주도록 설정하고 싶은데 Beanstalk 웹 콘솔에는 그런 설정이 없어 AWS CLI를 쓰거나 젠킨스 플러그인을 통해서만 가능했습니다.
* 배포 시간이 너무 길었습니다 (1대당 5분)
* 같은 Beanstalk 환경에서 특정 서버만 다르게 설정하는 것이 정말 불편합니다.

특히 마지막 2개 단점이 치명적이였습니다.  
  
AWS Beanstalk의 경우 한대 서버에 배포하는 시간이 5분이 필요합니다.  
**5대에 배포해야 할 경우 한대씩 5분이 걸리니 총 25분이 필요**했습니다.  
서버 교체가 아닌 단순히 Application만 배포하는데도 한 대당 5분씩 걸리는 것은 문제가 있다고 생각했습니다.
배포 대수를 30% 혹은 50%로 선택하기엔 무리가 있었습니다.  
배포하는 순간에 남은 서버들에 크게 부하가 증가하기 때문입니다.  
  
그래서 이 문제를 회피하기 위해 같은 설정의 Beanstalk를 하나더 생성해 반대편 환경에 100%로 배포하고 ELB를 스위칭 하는 방법 등을 고려했습니다.  
하지만 **배포하는게 이렇게 번거로워야하나?** 라는 아주 근본적인 생각이 들었습니다.  
  
또한 특정 서버만 다른 환경 설정이 어렵다는 것도 큰 문제였습니다.  
저희는 모니터링툴로 **Newrelic**과 **핀포인트**를 함께 쓰고 있습니다.  
두 솔루션에는 문제점이 하나 있었는데요.  
**Newrelic APM (인프라스트럭쳐 X) 와 핀포인트가 같이 운영되지 않습니다**.  
  
IDC를 사용할때는 큰 문제가 없었습니다.  
1번 서버는 Newrelic APM을, 나머지 서버들에는 핀포인트를 설치해서 쓰면 됐기 때문입니다.  
하지만 Beanstalk은 **환경 내의 특정 서버만 다른 설정을 갖도록 하는 것이 정말 어렵습니다**.  
불가능한 것은 아니지만, 사실상 개발자가 쉘스크립트로 다 짜야하는 상황이였습니다.  
  
이런 문제점들로 인해 시스템 오픈 하고 난 뒤, 팀의 개발자분이 직접 Code Deploy 전환을 진행하셨습니다.  
현재는 모든 포인트 시스템은 AWS Beanstalk을 제거하고 **ASG (Auto Scaling Group) & Code Deploy**로 완전히 전환되었습니다.  
그리고 위에서 언급한 단점들이 모두 해결되어 큰 문제없이 사용중입니다.

### 1-2. Spring SQS Listener vs Beanstalk Worker

Spring과 Beanstalk을 쓰고 있는 상황에서 AWS SQS에서 메세지를 수신할 수 있는 방법은 크게 2가지가 있습니다.

* Spring Cloud AWS 에서 제공하는 ```@SqsListener```
* AWS Beanstalk에서 제공하는 Worker (한글명으로는 작업자 환경입니다.)

AWS Beanstalk에서 제공하는 Worker 서비스를 사용하면 몇가지 장점이 있습니다.

* 모니터링이 쉽습니다.
    * 어플리케이션에서는 API형태로 Controller을 만들면 Beanstalk에서 SQS 메세지를 수신해 해당 API로 HTTP Request를 보냅니다.
    * 어플리케이션 입장에서는 일반적인 HTTP Request와 같기 때문에 모니터링이나 추적이 쉽습니다.
* 구축이 쉽습니다.
    * 기존에 HTTP API를 만들던 방법으로 그대로 어플리케이션을 구현하면 되니 메세징에 대해 신경쓰지 않고 구축할 수 있습니다.

하지만 저희는 Spring Cloud AWS 에서 제공하는 ```@SqsListener```를 선택했습니다.  

* 특정 벤더 (AWS)에 Lockin 되는 것은 좋지 않다고 생각했습니다.
    * 언제든 IDC로 혹은 다른 클라우드로 이동할 수 있게 구성되어야 한다고 생각했습니다.
* Beanstalk Worker 내부의 메세지 수신 데몬의 오류가 있을 경우 저희쪽에서 대응할 방법이 없습니다.
* 

실제로 이렇게 구축한 덕분에 시스템 안전화 이후 ASG & Code Deploy로 시스템 환경을 변경할때 큰 번거로움없이 진행될 수 있었습니다.  
만약 Beanstalk Worker를 사용했다면 Worker에서 해주는 부분을 어플리케이션에서 다시 구현해야 하고, 이 부분에 대한 성능 테스트와 QA를 또 했어야 했기 때문에 시도하지 못했을 것입니다.

### 1-3. Jenkins vs AWS Code Pipeline

개인 프로젝트에서는 AWS Code Pipeline을 사용하고 있습니다.

* [AWS로 배포하기](https://jojoldu.tistory.com/281)

아무래도 Code Build & Code Deploy & Code Pipeline으로 구축할 경우 **빌드 & 배포 시간에만 비용이 청구**되기 때문에 비용도 절약할 수 있고, 별도로 CI 시스템 구축할 필요도 없어서 선호했습니다.  

하지만 이번 포인트 시스템에서는 Jenkins + Beanstalk (현재는 Jenkins + Code Deploy로 전환)를 선택했습니다.  
  
그 이유는 다음과 같은데요.

* AWS Code Pipeline으로 [멀티 모듈 프로젝트](https://jojoldu.tistory.com/123) 를 구성하는게 쉽지 않았습니다.
* Jenkins 에 이미 익숙한 상태라 커스텀하게 배포 환경 구성이 필요해도 쉽게 구성할 수 있는 반면, AWS Code Pipeline은 자료가 생각보다 없어서 생각보다 삽질하는 시간이 필요했습니다.
* 저희 팀의 다른 서비스인 빌링과 정산은 IDC를 써야만 합니다. 그래서 젠킨스를 쓸 수밖에 없는데, 포인트 시스템만 AWS Code Pipeline 으로 사용하기엔 팀 컨벤션에 맞지 않다고 생각했습니다

마지막 이유가 가장 중요했습니다.  
결과적으로 팀의 모두가 CI/CD 서버에 대해서 다룰 수 있어야하는데, Jenkins 외에 다른 시스템을 도입할 경우 팀에게 부담을 주는 일이 될 수 있기 때문입니다.  
  
아마 팀 CI툴이 Teamcity였다면 마찬가지로 Teamcity를 선택했을 것입니다.  
어찌 됐든 이런 인프라 환경은 팀 컨벤션을 맞추는게 중요하다 생각했습니다.

## 2. 도메인

신규 포인트 시스템은 **Update와 Delete가 없는 도메인**으로 구성하였습니다.  
포인트는 일종의 기업 부채 혹은 재화와 비슷한 의미로 사용되기 때문에 그 이력은 아주 정확하고 상세하게 관리되어야만 했습니다.  

기존 시스템의 경우 Update가 있었기 때문에 **왜 이 회원의 포인트가 이 금액이 되었는지 정확히 추적하기가 어려웠습니다**  
현재 가용포인트와 실제로 적립/사용된 포인트의 계산이 안맞는 경우도 있었으며, 이럴 경우 틀어진 데이터를 수정해야하는데, 한번 틀어진 데이터를 다시 맞추기가 너무 어려웠습니다.  
  
### 2-1. 포인트 사용 & 차감

이렇게 Insert만 존재하는 도메인 모델에서 중요한건 

### 2-2. 포인트 유효 기간 만료


  


## 3. 시스템 아키텍처

이번 포인트 시스템의 아키텍처 기조는 **DB가 죽어도 문제 없는 서비스**였습니다.  
이를 위해서 AWS SQS를 적극적으로 사용했습니다.  
  
DB가 죽어도 문제 없는 서비스를 만들기 위해서 다음과 같이 구성하였습니다.

* RDS가 죽어도 SQS에는 이벤트 메세지들이 쌓여 있기 때문에 RDS가 복구되는 순간 처리 가능
* 가장 많이 사용되는 포인트 조회는 Redis 캐시를 통해 처리되니 RDS가 죽어도 시스템 문제가 없음
* Redis가 죽는 장애가 발생하면 바로 RDS를 통해 조회가 되도록 구성

특히 포인트 시스템을 가장 중요하게 사용하는 **주문 시스템과 결제 시스템도 마찬가지로 SQS로 비동기 시스템이 구축**되어 있습니다.  
  
그래서 포인트의 모든 서비스가 죽는다 하더라도, 주문 시스템과 결제 시스템은 자체 SQS에 메세지를 계속 담아두고 포인트 시스템이 다시 실행되면 그때 메세지를 일괄 발송하면 되므로 고가용성 시스템을 구축할 수 있었습니다.

![아키텍처1](./images//아키텍처1.png)

여기서 한가지 다른 점은 **포인트 사용은 SQS를 쓰지 않고 바로 데이터베이스에 반영한다**는 점입니다.  

스프링 배치를 통한 이벤트 처리 역시 point-edge 모듈을 통해서 처리되도록 했습니다.
포인트 차감이 즉시 되지 않으면, 포인트 중복 사용이 발생할 수 있음
포인트 사용 취소, 포인트 적립, 포인트 적립 취소, 포인트 전환은 큐를 통해 이벤트 등록한다

**SQS는 순서가 보장되지 않습니다**.  
그래서 주문 한 뒤, 바로 취소를 할 경우 상황에 따라 **취소가 먼저 오고, 적립이 이후에 올 수 있습니다**.  
이럴 경우 적립된 대상이 아직 없기 때문에 취소 이벤트는 실패하게 됩니다.  

취소할 대상이 없는 경우 Ack처리하지 않는다 (다시 SQS로 돌려보낸다라는 의미입니다) 로 문제를 해결했습니다.  
같은 메세지가 5번 실패하면 Dead Letter Queue로 반환되기 때문에 5번 취소대상을 찾았는데도 실패했다면 진짜 잘못된 메세지로 보는 것입니다.




## 4. 테스트

### 4-1. 단위 테스트와 통합 테스트

단위 테스트 & 통합 테스트 도구로는 **Junit4**와 **Spock**을 같이 사용했습니다.  
코드 리뷰 시간에 철저히 Feature 기능의 테스트 코드를 점검하기 때문에 단위 테스트 없이 절대 Merge 할 수는 없습니다.  
테스트 도구의 경우 Spock으로 점차 넘어가는 중이지만, 아직 Junit4가 익숙하신분이 계셔 Junit4를 사용해도 무방하다는 룰을 정했습니다.  
Spock을 연습하면서 프로젝트를 진행하기에는 시간이 그렇게 넉넉하지 않았기 때문입니다.  
  

### 4-2. Spring Cloud & AWS 테스트

신규 포인트 프로젝트의 큰 기조 중 하나는 "**Git Clone 받으면 바로 로컬 개발 환경 & 테스트가 실행될 수 있어야 한다**" 입니다.  
프로젝트 받은 뒤에 A도 해야하고, B도 해야하고, C도 해야만 로컬에서 실행할 수 있는 환경은 절대 하지 않기로 했습니다.  
  
하지만 이런 환경을 구축하는데 큰 걸림돌이 Spring Cloud AWS 코드의 테스트 환경 구축입니다.  


AWS RDS와 Elastic Cache에 대한 통합 테스트를 작성하는데는 큰 문제가 없었습니다.

AWS SQS에 대한 격리된 테스트 환경이 필요했습니다.

우아한 형제들에서는 자유롭게 AWS를 사용하고 테스트 할 수 있게 **놀이터**라는 샌드박스 존이 존재합니다.  

![sqs테스트1](./images/sqs테스트1.png)

개발자 A가 로컬에서 발송한 SQS 메세지가 개발자 B의 로컬에서 혹은 Jenkins에서 메세지를 수신해버려 개발자 A에서는 제대로 기능을 테스트 해볼수가 없습니다.  
즉, 모두가 접근할 수 있는 **공용 저장소를 사용하는 순간 서로가 서로의 테스트를 침범**하게 되어 격리된 테스트 환경 구축을 못하게 되버렸습니다.  
  
이건 굉장히 큰 문제라 생각했습니다.  
그래서 어떻게 하면 H2, Embedded Redis와 같이 격리된 SQS를 구축할 수 있을까 고민 하던 중, ElasticMQ를 발견했습니다.  

AWS의 메세징 큐 서비스인 SQS와 동일한 인터페이스를 가진 ElasticMQ를 Spring Boot에서 임베디드로 사용할 수 있게 랩핑한 라이브러리이다. 
즉, 의존성만 추가하면 H2 사용하듯이 SQS를 사용할 수 있게 해준다.

이렇게 라이브러리를 만들고 포인트 시스템 구축시에 사용해보니 로컬 개발하면서 한번도 서버를 실행해본적이 없다. 
모든걸 다 테스트 코드로만 실행하고 검증했다.

* 내가 만든 SQS Listner가 제대로 메세지를 수신하는지
* 내가 만든 QueueTemplate이 메세지를 제대로 송신하는지
* 내가 지정한 횟수만큼 실패시 Dead Letter Queue에 전달하는지
* 메세지가 원하는대로 JSON 전환되어 전달되는지

등등 Mocking으로 해결할 수 없는 테스트를 완전히 구현할 수 있었다.

브라우저로 테스트하는 것은 개발서버에 배포한 뒤에나 했다. 
근데 아무런 문제가 없었다. 
Spring Boot AWS Mock 을 기준으로 구현한 모든 코드들과 테스트 코드들이 실제 AWS 위에서도 의도한대로 잘 작동되었던 것이다.

이걸 계기로 AWS SQS도 테스트 코드를 작성할 수 있게 되었다. 
Jenkins에서 지속적으로 통합테스트를 수행할때도, 개발자 개개인의 로컬 PC에서 테스트를 수행할때도 서로 격리된 환경에서 SQS 관련 테스트 코드를 수행할 수 있게 되었다.


### 4-3. 레거시 프로시저 테스트

신규 도메인은 모두 JPA를 사용하고, 모든 로직은 어플리케이션에 있었기 때문에 H2를 사용해도 문제가 없었습니다.  

> 즉, Database에서 로직을 처리하는 password(), now(), 스토어드 프로시저 등을 전혀 사용하지 않습니다.

하지만 기존 레거시 시스템의 프로시저를 검증하기 위한 테스트 코드를 작성하는데 문제가 있었습니다.  
**H2는 MSSQL의 프로시저를 지원하지 않기 때문**입니다.  
  
이 문제를 어떻게 해결할까 고민하다가 이 **레거시 프로시저와 관련된 코드들을 테스트 할때만 Docker**를 사용하기로 결정했습니다.  
  
그래서 레거시 프로시저용 API를 담당하시는 개발자분의 **개인 PC와 지속적인 테스틀를 진행할 젠킨스 서버에 Docker로 MSSQL을 설치하고 기존 시스템의 프로시저를 모두 생성**했습니다.  

그리고 이렇게 작성한 테스트 코드와 Docker는 시스템이 더이상 이전 프로시저를 지원하지 않아도 되는 순간 일괄 삭제하여 깨끗한 프로젝트로 구성을 하였습니다.


### 4-4. HTTP API 테스트

일반적으로 **개발 서버에 배포된 서비스의 HTTP API 테스트**는 Postman을 사용합니다.  
(배포 전의 테스트는 당연히 단위 테스트 or 통합테스트 코드로 진행합니다.)  
  
저희는 팀 모두가 IntelliJ Ultimate 버전을 사용하고 있었기에 IntelliJ의 ```.http```를 사용하기로 결정했습니다.

* HTTP API 테스트에 대한 버전 관리 가능
* HTTP API 스펙을 팀원 모두가 공유 가능

## 5. API 문서 자동화

주문, 빌링, 정산, 회원, 쿠폰, 메인 프론트 등 여러 팀에서 포인트의 API를 사용해야 했기 때문에 API문서는 필수였습니다.  
하지만 **수동으로 작성하는 것은 언젠간 코드와 문서간에 간격이 발생**해서 문서 자동화에 대해 고민했었습니다.  
API 문서 자동화에 관한 솔루션들은 많습니다.

* Swagger
* Apidoc
* Spring Rest Docs

이 중에서 저희는 Spring Rest Docs를 선택했습니다.  
나머지 문서 자동화 솔루션들에는 개인적으로 생각하는 큰 단점들이 있었습니다.  

Apidoc의 경우 2가지 단점이 있었습니다.

* 문서를 사실상 수동으로 작성하는 것과 마찬가지라 문서와 코드가 따로 작동합니다 
* Apidoc을 위한 어노테이션이 프로덕션 코드를 오염시켰습니다

Swagger의 경우도 비슷한 단점이 존재했습니다.

* API를 테스트하기는 좋으나 Swagger 문서를 보고 연동 시스템을 만들기에는 부족한게 많습니다
* 프로덕션 코드가 Swagger 어노테이션으로 오염됩니다

반대로 Spring Rest Docs의 장점은 다음과 같습니다.

* 테스트 코드를 작성하면 문서로 자동 완성
    * 테스트 코드를 기준으로 문서가 만들어 지기에 프로덕션 코드에 관련된 코드가 전혀 필요 없음
    * 테스트 코드 기반이라 문서와 코드가 불일치하는 경우가 발생할수가 없음
* 테스트 코드로 표현하기 어려운 부분은 AsciiDoc 혹은 Markdown으로 작성 가능

Spring Rest Docs는 그간 제가 문서 자동화 솔루션들에 갖고 있던 불만을 모두 해결해주었습니다.  
즉, 테스트가 깨지면 문서가 만들어지지 않기 때문에 잘못된 API 문서가 발핼될일이 사전에 차단됩니다.  
특히, 저희 팀은 테스트 코드 작성이 팀 규칙상 필수였기 때문에 테스트 코드 기반의 문서 자동화 솔루션인 Spring Rest Docs는 아주 좋은 선택지였습니다.  

다만 단점도 있었는데요.

* 테스트 코드로 문서를 표현해야하기에 Rest Docs용 테스트 코드의 양이 비정상적으로 많습니다.

RequestDto와 ResponseDto의 각 필드의 모든 명세를 작성해야만 했습니다.




Spring Rest Docs를 사용하는 방법은 크게 2가지가 있습니다.  
AsciiDoc과 Markdown입니다.  
처음 Rest Docs를 고려했을때는 Markdown 타입을 사용하려고 했습니다.  
팀 전체가 AsciiDoc 보다는 Markdown에 더 친숙하기 때문이였습니다.  
  
하지만 Markdown 버전의 Spring Rest Docs를 사용하고는 포기했습니다.

* Ruby 라이브러리인 slate에 의존해야만 하는 구조
    * 팀 구성원 전체가 Ruby & Gem을 설치하고 bundler까지 설치해야하는게 너무 번잡합니다.
* 만들어지는 문서가 기존 스프링 관련 문서들에 비해 UI가 친숙하지 않습니다.
* 빌드 시간이 너무 오래 걸립니다.
    * Ruby 의존성들이 많아 빌드시간이 전체적으로 너무 오래걸립니다.

그래서 Spring Rest Docs는 AsciiDoc 버전으로 결정했습니다.  
현재는 포인트 시스템의 문서 자동화가 굉장히 잘 되어서 다른 서비스인 빌링, 정산 역시 문서를 Spring Rest Docs로 전환 중입니다.  
  
Spring Rest Docs 사용 방법은 블로그에 정리했으니 참고하시면 좋을것 같습니다.

* [Spring Rest Docs를 Markdown으로 작성하기](https://jojoldu.tistory.com/289)
* [Spring Rest Docs를 AsciiDoc으로 작성하기](https://jojoldu.tistory.com/294)

## 6. 브랜치 전략

저희 팀은 Git Branch 전략을 사용하고 있었습니다.  
하지만 포인트 시스템을 구축하는 과정에서는 이 전략을 사용하지 않았습니다.  

* 일정이 넉넉치 않았습니다.
    * 기존 도메인 분석 기간과 성능 테스트 & QA를 제외하면 실제 개발 가능한 시간이 2달채 되지 않았습니다.
* 시스템 구축에 투입된 개발자가 3명 이였으며, 3명이 완전히 독립적인 모듈을 담당했기 때문에 코드가 겹칠일이 거의 없었습니다.

3명의 담당은 아래와 같습니다.

* 레거시 프로시저를 API로 전환, 신규 포인트 시스템 어드민 개발
* 레거시 분석 및 레거시 데이터 신규 도메인 모델로 마이그레이션
* 신규 도메인 설계, 신규 도메인 API, AWS 인프라 구축

이렇게 완전히 영역이 분리되어 있어 굳이 Git Branch 모델을 쓰지 않고 **Master 브랜치**로만 모든 커밋을 추가했습니다.  
  
그리고 단일 브랜치의 장점을 살려 가장 먼저 개발 환경에서 Jenkins를 설치해 Master 브랜치에 Push가 발생하면 전체 테스트 수행과 개발 환경 배포를 
개발자는 자신이 작성한 단위 테스트만 검증하고 통합 테스트는 Jenkins가 대신 수행하도록 해 최대한 시간을 아끼려고 했습니다.

